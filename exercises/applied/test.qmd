# Lecture 2: Data loading and exploration

## Themes for today
* Read documentation, load data, replace incorrect values.
* Explore the data using plots and correlation matrices. 
* Writing computational essays.
* Walkthrough of exercise 2.4.9 in Introduction to Statistical Learning.
* After the lecture you should look at what a *submitted* variant of this exercise would look like. There are comments in the margin explaining what good stuff is being done.

## Exercise 2.4.9 {.unnumbered}
> This exercise involves the Auto data set studied in the lab. Make sure that the missing values have been removed from the data.

***N.B.*** Loading the data is in practice a subexercise (such as (a), (b), (c)), and should be treated as such. Most exercise in Introduction to Statistical Learning has an unlabeled load the data exercise, and sometimes it requires additional thought!


Skim the documentation first, it can be found [here.](https://islp.readthedocs.io/en/latest/datasets/Auto.html)

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```

```{python}
auto = pd.read_csv("data/auto.csv")
auto.head()
```

The `name` is the unique identifier of the car, similar to a primary key in relational databases. It's best to make this into an index column instead.

```{python}
auto = pd.read_csv("data/auto.csv", index_col="name")
auto.head()
```

It turns out that the `auto` data must be massaged a little more before usage. Take a look at the `info`:

```{python}
auto.info()
```

Here `horsepower` has type `object`; this is must be an error, because horsepower is a number, and should thus be `float64` or another numeric type.

The error is caused by missing values encoded as "?", as we can see here:

```{python}
np.unique(auto["horsepower"])
```

To remedy this, must call `read_csv` again, but with the special `na_values` argument. 

```{python}
auto = pd.read_csv("data/Auto.csv", na_values="?", index_col="name")
np.unique(auto["horsepower"])
```

We are still not done since one of the unique values equals `nan` (not a number), which many methods aren't able to use. There are ways to impute values for `nan`s, but we'll use the method `.dropna()` for now.

```{python}
auto = auto.dropna()
```

Finally, we can combine all these steps into one, which you should do in computational essays such as the exam. Just make sure to tell the reader why "name" is the index column; that "?" is understood as NA is considered self-explanatory.

```{python}
auto = pd.read_csv("data/Auto.csv", na_values="?", index_col="name").dropna()
```

Finally, `origin` is stored as a number, but should be a string. Recall the documentation:

> `origin`: Origin of car (1. American, 2. European, 3. Japanese)"

We can replace the integers with text using the `replace` method. 

```{python}
auto.replace({"origin": {1: "American", 2: "European", 3: "Japanese"}}, inplace = True)
auto.head()
```

### (a)
> Which of the predictors are quantitative, and which are qualitative?

All columns are quantitative except `origin` and `name`. This is evident from the [documentation,](https://islp.readthedocs.io/en/latest/datasets/Auto.html). The `year` variable can be interpreted both as qualitative and quantitative, but the other variables are clear-cut.

### (b)
> What is the range of each quantitative predictor? You can answer this using the `min()` and `max()` methods in Pandas.

In exercises like this, it's best to do exactly as you're asked. So don't use `.describe()`, use `.min()`, `.max`. 

One of the best ways to present data like this is to make a data frame out of them:
```{python}
pd.DataFrame({"min":auto.min(numeric_only=True), "max":auto.max(numeric_only=True)})
```

### (c)
> What is the mean and standard deviation of each quantitative predictor?
```{python}
pd.DataFrame({"mean":auto.mean(numeric_only=True), "std":auto.std(numeric_only=True)})
```


```{python}
auto.describe()
```

### (d)
There are two options here. First, you can select the required rows fro describe using the `loc` method.
```{python}
auto.describe().loc[["mean","std", "min", "max"]] 
```

Second, you can construct it all yourself. 
```{python}
auto_rem = auto.drop(auto.index[range(9, 85)])
out = pd.DataFrame({"mean":auto_rem.mean(numeric_only=True), "std":auto_rem.std(numeric_only=True), "min":auto_rem.min(numeric_only=True), "max":auto_rem.max(numeric_only=True)})
out
```

Moreover, you shouldn't show all digits here. It probably suffices with one or two significant digits.

```{python}
#| echo: false
out.style.format(precision=2)
```

Finally, 
```{python}
#| echo: false
#| tbl-cap: "Descriptive statistics for auto data."
out.style.format(precision=2)
```


**Note:** Make sure your presentation looks good. In this case that involves putting the columns into a dataframe.

### (e)
> Using the full data set, investigate the predictors graphically, using scatterplots or other tools of your choice. Create some plots highlighting the relationships among the predictors. Comment on your fndings.

**There is a lot to do in this exercise!**

The exercise is very open-ended, and there is so much to say. The following solution is one of many.

#### Correlations
2. Show you understand what the correlations mean, both the sign and the variables.
3. Show you can interpret the size of the correlations.


```{python}
pd.set_option("display.precision", 4)
auto.corr(numeric_only=True).style.format(precision=2)
```

Using `auto.drop("origin", axis=1).corr().round(1)` rounds the number of decimal places to $1$, which is appropriate for exploratory use of correlations (use $2$ when presenting correlations for other purposes).

Pandas has good support for coloring of tables, which is especially useful for correlation matrices. In particular, you may use the `style.background_gradient` method. (This is the only styler of pandas we require that you knwo.)
```{python}
auto.corr(numeric_only=True).style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)
```

Now let's take a look at the pairplot instead. 
```{python}
sns.pairplot(auto)
```

What comments do we look for here?

We already know which variables have high correlations. We are especially interested in non-linearities and interesting plots here.

First observe that the strong relationship between `acceleration`, `weight`, `horsepower`, and `displacement` is linear.

```{python}
sns.pairplot(auto[["acceleration", "weight", "horsepower", "displacement"]])
```

We'll have more to say about strong linear relationships between predictors l


```{python}
sns.lmplot(auto, x="mpg", y="horsepower")
```

We can continue analyzing this:
```{python}
sns.lmplot(auto, x="mpg", y="horsepower", lowess = True, col = "cylinders")
```

Now it seems there *is* a linear relationship between `mpg` and \ `horsepower`, provided we take `cylinders` into account. Such phenomena are common, and we say there is an interaction effect between `horsepower` and `cylinders` on `mpg`.

You can check if similar relationships hold for the other variables. There is less of an interaction between `weight` and `cylinders`.

```{python}
sns.lmplot(auto, x="mpg", y="weight", lowess = True, hue = "cylinders")
```

How about `origin` and `horsepower`?

```{python}
sns.lmplot(auto, x="mpg", y="horsepower", lowess = True, col = "origin")
```

The first plot doesn't look entirely linear. But we cal look at both `origin` and `horsepower` at the same time.

```{python}
sns.lmplot(auto, x="mpg", y="horsepower", lowess = True, col = "cylinders", hue = "origin", col_wrap=2)
```

From these plots it appears that all the interaction is due to `cylinders`. There only appears to be some interaction with origin because `cylinders` and `origin` are themselves associated with each other. 

```{python}
sns.countplot(auto,x="cylinders",hue="origin")
```

### (f)
>  Suppose that we wish to predict gas mileage (mpg) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg? Justify your answer.

We have done most of the hard work in the previous exercise, we are only missing the relationship between `origin` and `mpg`. We can visualize it using a *violin plot*.

```{python}
#| echo: false
#| fig-cap: "American cars have the highest miles per gallon, Japanese cars the lowest, and European are in-between."
sns.violinplot(auto,x="mpg", hue="origin")
```

There seems to be some assocition between the origin and mpg. In particular, American cars have lower miles-per-gallon. 

In summary, we find that all variables could be useful in predicting `mpg`. 

1. `cylinders`, `displacement`, `horsepower` and `weight` are strongly related to `mpg`, with correlations about `0.8`. They are however strongly correlated with each other too. `cylinders` is, unlike the other variables, an integer variable.
2. There is an interaction effect between `cylinders` and `horsepower`. Due to the high correlation between `horsepower`, `displacement`, and `weight`, there is likely to be an interaction between `cylinders` and those variables as well.
3. The variables `acceleration` and year have a decently strong correlation with `mpg`. Not surprisingly, the correlation between `mpg` and `acceleration` is negative.
4. Production year is positively associated with `mpg`. This is probably due to improvement in car technology. Engines, for instance, get more and more efficient each year.
5. There is a relationship between `mpg` and country of origin, but Japanese and European cars are very similar.

## Summary

#### Style (this might wait)
* Use `#| echo: False` to hide code. This is useful if the reader does not need to see your code to understand the presentation. It is especially useful for plots and tables.
* Figures can be given captions with `#| fig-cap: -caption here-`. 
* Tables can be given captions with `#| tbl-cap: -caption here-`. 
* All figures and tables in your final report should have captions, except when the code is visible. Moreover, the content of the captions should be also be in the text body. 

#### Loading and descriptive statistics
* `pd.read_csv()` imports data. Be sure to use the arguments `index_col` and `na_values` if necessary!
* `dropna()` removes unwanted `nan` values from the dataframe.
* `.info()` displays information about data types, number of columns, and number of rows. Look at it along with the documentation to check if all data has been imported correctly.
* `.describe()` displays basic descriptive statistics. It is used to get a feel for the dataset.
* `.min()`, `.max()`, `.std()`, and `.mean()` are functions that calculates the minimum / maximum / standard deviation / mean for the entire dataset. There are other functions in the same category, for instance `quantile` for quantiles and `median` for the median. You may have to use the argument `numeric_only=True` to avoid errors.
* `value_counts` finds the unique values and counts them.
* `np.corrcoef` calculates the correlation of two Numpy arrays. Use it to calculate isolated correlations, when the full strength of `df.corr()` is not needed.

#### Exploration
* `df.corr()` Displays the correlation matrix between all variables in a data frame. Best used as the long `df.corr(numeric_only=True).style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)`, which creates as colored correlation matrix with suitable precision.
* Correlations are [...]
* "df.plot` contains several plotting methods working directly on the frame, e.g. `plot(kind=bar)` for bar plots, `plot.hist()` for histograms, and `plot.kde()` for kernel density estimators.
* `sns.pairplot(frame)` Creates scatter plot between all numerical variables in a frame and a diagonal of histograms. The most important exploratory plotting function.
* The pairplot should be made after the correlation matrix has been displayed, and comments should be written with reference to the correlation matrix, with special emphasis on linearity and non-linearity.
* `sns.countplot(frame)` Use to count the number of elements in classes. Useful when none of the inputs are decimal numbers (`float64`).
* `sns.violinplot(frame)` Constructs violinplots, i.e., estimated densities. Useful when you want to see the relationship between a qualitative and decimal column.
* `sns.lmplot(frame)` Used to plot the relationship between several variables. Especially useful when used with the `hue` and / or `col` argument, which lets you hunt for *interactions*.
