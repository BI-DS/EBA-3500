{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"EBA35002 Fall 2022\"\n",
        "subtitle: Written exam\n",
        "author: Jonas Moss\n",
        "format:\n",
        "  html:\n",
        "    embed-resources: true\n",
        "    colorlinks: true\n",
        "editor: visual\n",
        "---"
      ],
      "id": "43ea8ef0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All subexercises are equally weighted.\n",
        "\n",
        "## 1 Mathematical questions\n",
        "\n",
        "We have $n$ independent observations $X_1,X_2,\\ldots,X_n$ from the log-normal distribution $$\n",
        "f(x;\\mu,\\sigma)=\\frac{1}{x\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{(\\ln x-\\mu)^{2}}{2\\sigma^{2}}\\right),\\quad x\\in(0,\\infty).\n",
        "$$\n",
        "\n",
        "Use the following properties freely in the following exercises.\n",
        "\n",
        "1.  $X$ is log-normally distributed with parameters $\\mu,\\sigma$ if and only if $\\log X$ is normally distributed with parameters mean $\\mu$ and variance $\\sigma^{2}$.\n",
        "2.  The mean of a log-normal $X$ is $EX=e^{\\mu+\\frac{\\sigma^{2}}{2}}$ and its variance is $(e^{\\sigma^{2}}-1)e^{2\\mu+\\sigma^{2}}$.\n",
        "3.  $\\hat{\\mu} = \\overline{\\log X}$ is the maximum likelihood estimator of $\\mu$ and the biased sample variance $\\widehat{\\sigma^2} = \\sum_{i=1}^{n}(\\log X_{i}-\\overline{\\log X})^{2}/n$ is the maximum likelihood estimator of $\\sigma^{2}$.\n",
        "4.  The Fisher information matrix of $(\\mu,\\sigma^{2})$ is $$\n",
        "    I(\\mu,\\sigma^{2})=\\left[\\begin{array}{cc}\n",
        "    \\frac{1}{\\sigma^{2}} & 0\\\\\n",
        "    0 & \\frac{1}{2\\sigma^{4}}\n",
        "    \\end{array}\\right].\n",
        "    $$\n",
        "\n",
        "### 1.a.\n",
        "\n",
        "There are two ways to show that $\\sqrt{n}(\\overline{\\log X}-\\mu)$ converges in distribution to $N(0,\\sigma^2)$. What are these two?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "By the central limit theorem and property (2) above, the asymptotic distribution of $\\sqrt{n}(\\overline{\\log X}-\\mu)$ is normal with standard deviation $\\sigma$. (b) You can also use the fact that the maximum likelihood estimator converges in distribution to a normal distribution with covariance matrix $I^{-1}$.\n",
        ":::\n",
        "\n",
        "### 1.b.\n",
        "\n",
        "What is the asymptotic distribution of $\\sqrt{n}(\\overline{X}-E(X_{1}))$?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "By the central limit theorem and property (3) above, the asymptotic distribution of $\\sqrt{n}(\\overline{X}-\\mu)$ is normal with standard deviation $\\sqrt{(e^{\\sigma^{2}}-1)e^{2\\mu+\\sigma^{2}}}$.\n",
        ":::\n",
        "\n",
        "### 1.c.\n",
        "\n",
        "One can show that the median of the log-normal distribution is $e^{\\mu}$. What is the maximum likelihood estimator of $e^{\\mu}$?\n",
        "\n",
        "::: {.callout-note collapse=\"true\" }\n",
        "#### Solution\n",
        "\n",
        "By the invariance principle, the maximum likelihood estimator of $e^\\mu$ is $e^{\\hat{\\mu}},$ where $\\hat{\\mu}$ is the maximum likelihood estimator of $\\mu$.\n",
        ":::\n",
        "\n",
        "### 1.d\n",
        "\n",
        "What is the asymptotic distribution of $\\sqrt{n}(e^{\\overline{\\log X}}-e^{\\mu})$?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "By the delta method, the asymptotic distribution is normal with standard deviation $|g'(\\mu)|\\sigma$. Now $g(\\mu) = e^\\mu$ has derivative $g'(\\mu) = e^\\mu$, hence the standard deviation is $e^\\mu\\sigma$.\n",
        ":::\n",
        "\n",
        "### 1.e.\n",
        "\n",
        "What is the maximum likelihood estimator of the mean of $X_{1}$?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "Using the invariance principle and point (3), the maximum likelihood estimator is $e^{\\hat{\\mu} + \\widehat{\\sigma^2}/2}$\n",
        ":::\n",
        "\n",
        "### 1.f.\n",
        "\n",
        "Let $g(x,y)=e^{x+\\frac{y}{2}}$. Calculate the partial derivatives $$\n",
        "\\frac{\\partial g}{\\partial x},\\quad\\frac{\\partial g}{\\partial y}.\n",
        "$$\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "The partial derivatives are $e^{x+y/2}$ and $\\frac{1}{2}e^{x+y/2}$.\n",
        ":::\n",
        "\n",
        "### 1.g.\n",
        "\n",
        "Let $\\theta$ be a $k$-dimensional vector parameter and $g: \\mathbb{R}^k \\to \\mathbb{R}$ be a continuously differentiable function. Moreover, suppose $\\sqrt{n}(\\hat{\\theta} -\\theta)\\stackrel{d}{\\to} N(0,\\Sigma)$. What is the asymptotic distribution of $\\sqrt{n}(g(\\hat{\\theta})-g(\\theta))$? What is the name of this result?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "The *delta method (rule)* states that $\\sqrt{n}(g(\\hat{\\theta})-g(\\theta))$ converges to a normal with variance $\\nabla g(\\theta)^T \\Sigma \\nabla g(\\theta)$, where $\\nabla g(\\theta)$ is the gradient of $g$ at $\\theta$.\n",
        ":::\n",
        "\n",
        "### 1.h.\n",
        "\n",
        "Show that the asymptotic distribution of the maximum likelihood estimator in 1.e., i.e., $\\sqrt{n}(\\hat{\\theta}_{ML}-\\theta)$, where $\\theta = e^{\\mu + \\sigma^2/2}$, has variance $\\sigma^2(1+\\frac{1}{2}\\sigma^2) e^{2\\mu + \\sigma^2}$.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "We use the delta method $g^T\\Sigma g$, where $\\Sigma$ is the inverse Fisher information. Then, putting $\\theta = e^{\\mu + \\sigma^2/2}$, \\begin{eqnarray*}\n",
        "\\left[\\begin{array}{c}\n",
        "\\theta\\\\\n",
        "\\frac{1}{2}\\theta\n",
        "\\end{array}\\right]^{T}\\left[\\begin{array}{cc}\n",
        "\\sigma^{2} & 0\\\\\n",
        "0 & 2\\sigma^{4}\n",
        "\\end{array}\\right]\\left[\\begin{array}{c}\n",
        "\\theta\\\\\n",
        "\\frac{1}{2}\\theta\n",
        "\\end{array}\\right] & = & \\left[\\begin{array}{c}\n",
        "\\theta\\\\\n",
        "\\frac{1}{2}\\theta\n",
        "\\end{array}\\right]^{T}\\left[\\begin{array}{c}\n",
        "\\theta\\sigma^{2}\\\\\n",
        "\\theta\\sigma^{4}\n",
        "\\end{array}\\right]\\\\\n",
        " & = & \\theta^{2}\\sigma^{2}+\\frac{1}{2}\\theta^{2}\\sigma^{4}.\n",
        "\\end{eqnarray*} Since $\\theta^2 = e^{2\\mu + \\sigma^2}$ the desired expression is true.\n",
        ":::\n",
        "\n",
        "### 1.i.\n",
        "\n",
        "Now we have two estimators of $EX_{1}$. Which one should you prefer? You may use that $e^{x^2} > \\frac{1}{2} x^4 - x^2 + 1$ whenever $x\\neq 0$.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "(a) You may argue that maximum likelihood estimators are efficient, hence you prefer the maximum likelihood estimator.\n",
        "(b) You may use the fact that $e^{x^2} > \\frac{1}{2} x^4 - x^2 + 1$ whenever $x\\neq 0$ and that the asymptotic variances of the two methods are $$\\ensuremath{\\sigma^{2}(1+\\frac{1}{2}\\sigma^{2})e^{2\\mu+\\sigma^{2}}}<(e^{\\sigma^{2}}-1)e^{2\\mu+\\sigma^{2}},$$ now divide by $e^{2\\mu+\\sigma^{2}}$ on both sides to get $$ \\ensuremath{\\sigma^{2}(1+\\frac{1}{2}\\sigma^{2})}<(e^{\\sigma^{2}}-1),$$ when we add $1$ to both sides, we obtain $$\\ensuremath{\\sigma^{2}+\\frac{1}{2}\\sigma^{4}}+1<e^{\\sigma^{2}}.$$ Thus the maximum likelihood estimator has the smallest variance for any $\\sigma^2>0$.\n",
        ":::\n",
        "\n",
        "### 1.j\n",
        "\n",
        "Construct an approximate $95\\%$ confidence interval for the expectation $E(X_1)$ using the maximum likelihood method.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "Suppose that $\\sqrt{n}(\\hat{\\theta} - \\theta) \\to N(0, \\tau)$. Using the $Z$-interval construction, a $(1-\\alpha)\\%$ confidence interval for $\\theta$ is $$CI(\\theta; 1-\\alpha) = [\\hat{\\theta} - \\Phi^{-1}(1-\\alpha/2)\\sqrt{\\tau}/\\sqrt{n}, \\hat{\\theta} + \\Phi^{-1}(1-\\alpha/2)\\sqrt{\\tau}/\\sqrt{n}],$$ where $\\Phi^{-1}$ is the quantile function of the normal distribution, called ppf in Scipy. Recall that $$\\Phi^{-1}(1-\\alpha/2)\\approx 1.96$$ when $\\alpha = 0.95$\n",
        "\n",
        "Thus an approximate confidence interval is $$CI(\\theta; 1-\\alpha) = [\\hat{\\theta} - \\Phi^{-1}(1-\\alpha/2)\\sqrt{\\tau}/\\sqrt{n}, \\hat{\\theta} + \\Phi^{-1}(1-\\alpha/2)\\sqrt{\\tau}/\\sqrt{n}],$$ Now plug in $\\hat{\\theta} = e^{\\hat{\\mu} + 0.5\\widehat{\\sigma^2}}$ and $\\hat{\\tau} = \\sigma^2(1+\\frac{1}{2}\\sigma^2) e^{2\\mu + \\sigma^2}$.\n",
        ":::\n",
        "\n",
        "### 1.k\n",
        "\n",
        "Using the results in the previous exercise, construct a confidence interval for y when $\\overline{\\log X} = 1$ and $\\overline{(\\log X^2} = 2$.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "We use that the unbiased sample variance can be written as \\begin{eqnarray*}\n",
        "\\widehat{\\sigma^{2}}=\\sum_{i=1}^{n}(Y_{i}-\\overline{Y})^{2}/n & = & \\overline{Y^{2}}-\\overline{Y}^{2}\\\\\n",
        " & = & 2-1\\\\\n",
        " & = & 1\n",
        "\\end{eqnarray*} And then $$\n",
        "\\hat{\\mu}=\\overline{Y}=1\n",
        "$$ \\begin{eqnarray*}\n",
        "e^{\\hat{\\mu}+\\frac{1}{2}\\widehat{\\sigma^{2}}} & = & e^{\\hat{\\mu}+\\frac{1}{2}\\widehat{\\sigma^{2}}}\\\\\n",
        " & = & e^{1+\\frac{1}{2}1}\\\\\n",
        " & = & e^{3/2}.\n",
        "\\end{eqnarray*} Moreover, $${\\sqrt{\\hat{\\sigma}^{2}(1+\\frac{1}{2}\\hat{\\sigma}^{2})e^{2\\hat{\\mu}+\\hat{\\sigma}^{2}}}}=\\sqrt{\\frac{3}{2}e^{3}}=\\sqrt{\\frac{3}{2}}e^{3/2}.$$ Plug this into the confidence interval to obtain $$e^{3/2}\\pm e^{3/2}\\sqrt{\\frac{3}{2}}\\cdot1.96/\\sqrt{n}.$$\n",
        ":::\n",
        "\n",
        "## 2 Regression questions\n",
        "\n",
        "### 2.a\n",
        "\n",
        "Consider the following code:\n"
      ],
      "id": "854fd196"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "weather = pd.read_csv(\"weatherAUS.csv\")\n",
        "weather.RainToday = 1 * (weather.RainToday == \"Yes\")\n",
        "weather.RainTomorrow = 1 * (weather.RainTomorrow == \"Yes\")\n",
        "model = smf.logit(\"RainTomorrow ~ Location + RainToday\", data = weather).fit(disp=0)\n",
        "\n",
        "print(f\"weather.Location.dtype = {weather.Location.dtype}\")\n",
        "print(f\"model.llf = {model.llf}\")\n",
        "print(f\"model.llnull = {model.llnull}\")"
      ],
      "id": "f9a53955",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  Alice wants to use the model `\"RainTomorrow ~ C(Location) + RainToday\"` instead of `\"RainTomorrow ~ Location + RainToday\"`. Is this a good idea?\n",
        "2.  Use `llf` and `llnull` to reproduce McFadden's $R^2$. (I.e., what you get from `model.prsquared`).\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "1.  Doesn't matter what you do, since `Location` is categorical.\n",
        "2.  You must write `1 - model.llf/model.llnull`.\n",
        ":::\n",
        "\n",
        "### 2.b\n",
        "\n",
        "Suppose you have $3$ categorical covariates `a,b,c` with $14$, $3$ and $9$ levels each. How many regression coefficients are there in the model `y~a+b*c`? How about `y ~ a*b*c`?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "1.  There are $14 + 3\\cdot 9 = 41$ coefficients all in all, including the intercept.\n",
        "2.  There are $14\\cdot3\\cdot9 = 378$ coefficients all in all, including the intercept.\n",
        ":::\n",
        "\n",
        "### 2.c\n",
        "\n",
        "Consider the following code:\n"
      ],
      "id": "20303f9a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "cpssw8 = sm.datasets.get_rdataset(\"CPSSW8\", \"AER\").data\n",
        "model = smf.ols(\"np.log(earnings) ~ age + region\", data = cpssw8).fit()\n",
        "print(model.params)\n",
        "print(set(cpssw8.region))\n",
        "params = np.array(model.params)\n",
        "print(params)"
      ],
      "id": "b578a59f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  What would have been the value of `region[T.Midwest]` in the regression model `np.log(earnings) ~ age + region - 1`?\n",
        "2.  Write a Python function of `params` to predict the log-earnings of a 40 year old living in the South,\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "1.  It equals the intercept of the current model.\n",
        "2.  You would write a function that returns `params[0] + params[2] + 40 * params[4]`.\n",
        ":::\n",
        "\n",
        "### 2.d\n",
        "\n",
        "Bob's in big trouble! His boss Alice wants him to do a linear regression `lwage ~ age + gender`, where `lwage` is a centered measure of wages in Alice's company. But Bob has somehow managed to throw away her `lwage` data, replacing it with the variable `dwage = 1 * (lwage >= 0)` instead! What should Bob do to fulfill her boss's wish, and why would it work?\n",
        "\n",
        "::: {.callout-note collapse=\"true\"}\n",
        "#### Solution\n",
        "\n",
        "Bob should use Probit regression `dwage ~  age + gender`. It works since, if the residual error is normal, the probit model is equivalent to the model `lwage ~ age + gender` in our current setting.\n",
        ":::"
      ],
      "id": "ce625752"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}