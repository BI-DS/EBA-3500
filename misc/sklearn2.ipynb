{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Functions in `sklearn` {.unnumbered}\n",
        "\n",
        "\n",
        "## Functions in `matplotlib` and `seaborn`\n",
        "\n",
        "## Functions and methods in `pandas`\n",
        "We assume basic knowledge of `pandas` this course, e.g., \n",
        "\n",
        "\n",
        "\n",
        "| Name                          | Description           | Examples  | Lecture   |\n",
        "| ----------------------------- | -------------------   | -------   | -------   |\n",
        "| .read_csv()                   |                       |           | 8         |              \n",
        "| .head()                       |                       |           | 8         |\n",
        "| .info()                       |                       |           | 8         |\n",
        "| .dtypes()                     |                       |           | 8         |\n",
        "| .describe()                   |                       |           | 8         |\n",
        "| .value_counts()               |                       |           | 8         |\n",
        "| .astype()                     |                       |           | 8         |\n",
        "| .sort_values()                |                       |           | 8         |\n",
        "| .reset_index()                |                       |           | 8         |\n",
        "| Indexing with []              |                       |           | 9         |\n",
        "| Filtering with bools          |                       |           | 9         |\n",
        "| `.loc`                        |                       |           | 9         |\n",
        "| `.iloc`                       |                       |           | 9         |\n",
        "| `concat` `merge`              |                       |           | 9         |\n",
        "| `.isna()`                     |                       |           | 10        |\n",
        "| `.dropna()`                   |                       |           | 10        |\n",
        "| `.fillna()`                   |                       |           | 10        |\n",
        "| `.sum()`                      |                       |           | 10        |\n",
        "| `.cut()`                      |                       |           | 10        |\n",
        "| `.groupby()`                  |                       |           | 10        |\n",
        "| `.pivot_table()`              |                       |           | 10        |\n",
        "| `.crosstab()`                 |                       |           | 10        |\n",
        "| `.plot()`                     |                       |           | 11        |\n",
        "| Axes and subplots             |                       |           | 12        |\n",
        "| `sns.lineplot`                |                       |           | 12        |\n",
        "| `sns.countplot`               |                       |           | 12        |\n",
        "| `sns.barplot`                 |                       |           | 12        |\n",
        "| `sns.heatmap`                 |                       |           | 12        |\n",
        "| `sns.histplot`                |                       |           | 12        |\n",
        "| `sns.jointplot`               |                       |           | 12        | \n",
        "| `sns.pairplot`                |                       |           | 12        |\n",
        "| `sns.FacetGrid`               |                       |           | 12        |\n",
        "\n",
        "### `pandas` recap\n",
        "\n",
        "#### Lecture 8\n",
        "* Series, their values and indices.\n",
        "* Dataframe, creation from dictionaries, with indices.\n",
        "* `read_csv`, `head`, and `info`.\n",
        "* Show datatypes with `dtypes` for the dataframe and `dtype` for a series.\n",
        "* `describe()`.\n",
        "* `value_counts()`.\n",
        "* `astype`.\n",
        "* Sorting with `sort_values`.\n",
        "* Using `inplace=True`.\n",
        "* `reset_index`.\n",
        "\n",
        "#### Lecture 9\n",
        "* Selection by index with []; selecting multiple indices.\n",
        "* Filtering by boolean arrays.\n",
        "* Logical operators in selection.\n",
        "* Selection with `.loc`.\n",
        "* Selection with `.iloc`.\n",
        "* Concatenation with `concat`.\n",
        "* Merging data frames with `merge`.\n",
        "\n",
        "**Attributes**\n",
        "df.index, df.columns, \n",
        "\n",
        "#### Lecture 10\n",
        "* `.isna()`,\n",
        "* `.dropna()`,\n",
        "* `.fillna()`,\n",
        "* `.sum()`,\n",
        "* `.cut()`,\n",
        "* `.groupby()`,\n",
        "* `.pivot_table()`,\n",
        "* `.crosstab`.\n",
        "\n",
        "#### Lecture 11\n",
        "* `plt.plot`: Line plot, scatter plot, bar plot.\n",
        "* `sns.lineplot`\n",
        "* `sns.countplot`\n",
        "* `sns.barplot`\n",
        "* `sns.heatmap`\n",
        "* `sns.histplot`\n",
        "* `sns.pairplot`\n",
        "* `sns.FacetGrid`\n",
        "\n",
        "\n",
        "### Data cleaning and missing values\n",
        "\n",
        "Data cleaning:\n",
        "* Split columns.\n",
        "* \n",
        "https://datascientyst.com/exploratory-data-analysis-pandas-examples/\n",
        "https://bookdown.org/rdpeng/exdata/exploratory-data-analysis-checklist.html\n",
        "\n",
        "### Outliers\n",
        "* Use visual explanation of box plots in lecture.\n",
        "* Show how to find the outliers.\n",
        "* Mention there is a lot of stuff about this.\n",
        "* Have some exercises where it matters.\n",
        "\n",
        "### Imbalanced data\n",
        "\n",
        "### Data leakage\n",
        "* Find a good source on this at the correct level.\n",
        "\n",
        "* Having the target as a feature.\n",
        "\n",
        "#### Invalid processing\n",
        "* The example from Elements of Statistical Learning.\n",
        "* All data processing must be done using only the training data.\n",
        "* Exploratory data analysis is usually fine, but no always.\n",
        "* Separate into train and test in the beginning.\n",
        "* Do all modelling steps in cross-validation:\n",
        "    * Feature scaling.\n",
        "    * Feature selection.\n",
        "    * And so on.\n",
        "* https://www.cs.umb.edu/~ding/history/470_670_fall_2011/papers/cs670_Tran_PreferredPaper_LeakingInDataMining.pdf\n",
        "    * (i) An \"account number\" feature, for the problem of predicting whether a potential customer would open an account at a bank. Obviously, assignment of such an account number is only done after an account has been opened. \n",
        "    * (ii) An \"interviewer name\" feature, in a cellular company churn prediction problem.\n",
        "    * **Anachronisms.**\n",
        "        * Was feature $x$ registered before or after the event $y$?\n",
        "            * IBM example.\n",
        "    * Find some data sets with data leakage.\n",
        "\n",
        "### Embarassing mistakes\n",
        "* Understanding your domain.\n",
        "\n",
        "### Formatting and styling\n",
        "\n",
        "* style.highlight_between():\n",
        "    * Highlight negative values.\n",
        "* style.highlight_max(), style_highlight_min().\n"
      ],
      "id": "c3d6f005"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.random.seed(24)\n",
        "df = pd.DataFrame({\"A\": np.linspace(1, 10, 10)})\n",
        "df = pd.concat([df, pd.DataFrame(np.random.randn(10, 4), columns=list(\"BCDE\"))], axis=1)\n",
        "df.iloc[3, 3] = np.nan\n",
        "df.iloc[0, 2] = np.nan\n",
        "df."
      ],
      "id": "441283ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New functions\n",
        "\n",
        "\n",
        "We use several functions in `pandas`, `matplotlib`, and `seaborn` that haven't been covered, in addition to several `numpy` functions and some `statsmodels` functions.\n",
        "\n",
        "| Name                          | Library               | Description         | Examples |\n",
        "| ----------------------------- | --------------------- | ------------------- | -------  |\n",
        "| .corr()                       | `pandas`              | Correlation matrix.  | \n",
        "| .dtype()                      | `pandas`              | Data type for series. |\n",
        "| .min() / .max()               | `pandas` / `numpy`    | Find minimal / maximal value. \n",
        "| .argmin() / .argmax()         | `pandas` / `numpy`    | Find index of the minimal / maximal values. | \n",
        "| .nonzero()                    | `pandas`              | \n",
        "| .all() / .any()               | `pandas` / `numpy`    | Check if every element of an array is `True`.    \n",
        "| .replace()                    | `pandas`              | Replace values in data frame or series. Often used to replace strings with numbers. |\n",
        "| .to_numpy()                   | `pandas`              | Converts data frame or series to Numpy | \n",
        "| .lmplot                       | `seaborn`             | \n",
        "| .style.format                 | `pandas`              | Format data frames for visual inspection. |\n",
        "| .std / .var                   | `pandas` / `numpy`    | Standard deviation and variance. |\n",
        "| .mean / .median               | `pandas`              | Mean and median.\n",
        "| style.background_gradient     | `pandas`              | Styling of data frames with colors. Important for correlation matrices. | \n",
        "| .query()                      | `pandas`              | Selecting rows from a dataset using specialized syntax.\n",
        "| .boxplot()                    | `seaborn`             | \n",
        "| .violinplot()                 | `seaborn`             |\n",
        "| .sort_index()                 | `seaborn`             |\n",
        "| .log()                         | `numpy`               | Natural logarithm.                      \n",
        "| .log1p()                       | `numpy`               | Narural logarithm of $1+x$.\n",
        "| .sample()                     | `pandas` | \n",
        "| .shape |                      | `pandas` / `numpy`\n",
        "| .describe(include='object')   | `pandas` | \n",
        "| .nunique() / .unique()                    | `pandas` | \n",
        "| sns.catplot()                 | `pandas` |\n",
        "\n",
        "\n",
        "## Functions in `sklearn`\n",
        "[`sklearn`](https://scikit-learn.org/stable/index.html), also known as scikit-learn, is the most important Python library for fitting machine learning model. It has strong support for basic functionality such as metrics, cross-validation, fitting algorithms, and feature manipulation. That said, it is a big library, and we only use parts of it. \n",
        "\n",
        "The following is a complete list of `sklearn` functions used in this course, and we expect some familiarity with all of them. No exercise requires you to use any other function than those on this list, and all of them have been covered in the lectures. In the same way, the exercises on the exam will only use functions on this list.\n",
        "\n",
        "\n",
        "\n",
        "### Model selection and evaluation\n",
        "\n",
        "| Name                                                                                                                                                        | Module            | Usage                                                                                 | Examples |\n",
        "|-------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------|---------------------------------------------------------------------------------------|----------|\n",
        "| [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) | `model_selection` | Cross-validation for a specified score.                                                           |          |\n",
        "| [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)          | `model_selection` | Cross-validation over a grid of values. Used to find the hyperparameters for a model.                                |          |\n",
        "| [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)                                               | `metrics`         | Calculate the confusion matrix of a classifier.                                       |          |\n",
        "| [`r2_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)                                      | `metrics`         | The $R^2$ score. Default score for most regression methods. Usually available through `reg.score()`.                           |          |\n",
        "| [`mean_absolute_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)     | `metrics`         | The mean absolute error score in regression, $\\text{MAE}=\\sum_{i=1}^n|\\hat{y_i}-y_i|$ |          |\n",
        "| [`mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)        | `metrics`         | The mean squared error score in regression,$\\text{MSE}=\\sum_{i=1}^n(\\hat{y_i}-y_i)^2$ |          |\n",
        "| [`log_loss`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss)                                      | `metrics`         | The log loss, or cross-entropy loss, for classification.                              |          |\n",
        "| [`auc`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc)                                                     | `metrics`         | The area under the ROC curve, used in classification.                                     |          |\n",
        "| [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) | `metrics` | Accuracy classification score. Default score for most classification methods. Usually available through `clf.score()`. | |\n",
        "\n",
        "### Visualization\n",
        "\n",
        "| Name                                                                                                                                                             | Module                   | Usage                                                                     | Examples |\n",
        "|------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------|---------------------------------------------------------------------------|----------|\n",
        "| [`DecisionBoundaryDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html)                                   | `inspection`             | Plot the decision boundary for a classifier taking two features as input. |          |\n",
        "| [`RocCurveDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay)                      | `metrics`                | Display the ROC curve of a classifier.                                    |          |\n",
        "| [`ConfusionMatrixDisplay`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay) | `ConfusionMatrixDisplay` | Display the confusion matrix of a classifier.                             |          |\n",
        "| [`plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree) | `tree` | Display a fitted decision tree.                             |          |\n",
        "\n",
        "### Models\n",
        "\n",
        "| Function                                                                                                                                                                                                                                                                                                                          | Module         | Usage                                            | Examples |\n",
        "|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------|--------------------------------------------------|----------|\n",
        "| [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) / [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)                                                                               | `linear_model` | Fit a LASSO model with or without CV.            |          |\n",
        "| [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) / [RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)                                                                               | `linear_model` | Fit a Ridge model with or without CV.            |          |\n",
        "| [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso) / [ElasticNetCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)                                                                     | `linear_model` | Forward an elastic net model with or without CV. |          |\n",
        "| [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)                                                                                                                                                                            | `linear_model` | Fit a linear regression model.                   |          |\n",
        "| [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) / [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV) | `linear_model` | Fit a logistic regression model.                 |          |\n",
        "| [LinearDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis)                                                                                                                            | `discriminant` | Fit an LDA model.                                |          |\n",
        "| [QuadraticDiscriminantAnalysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)                                                                                                                   | `discriminant` | Fit a QDA model.                                 |          |\n",
        "| [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)                                                                                                                                                                                                | `naive_bayes`  | Fit a Gaussian Naive Bayes model.                |          |\n",
        "| [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) / [tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)             | `tree`         | Fit a decision tree.                             |          |\n",
        "| [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) / [KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor)          | `neighbors`    | Fit a $k$ nearest neighbors classifier.                        |          |\n",
        "| [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier) / [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor)          | `ensemble`    | Gradient boosting for regression or clasification.               |          |\n",
        "| [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) / [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)          | `ensemble`    | Random forests for regression or clasification.               |          |\n",
        "\n",
        "### Preprocessing\n",
        "\n",
        "| Function                                                                                                                                                                                    | Module              | Usage                                                      | Examples |\n",
        "|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------|------------------------------------------------------------|----------|\n",
        "| [`FeatureUnion`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)                                                                                      | `pipeline`          | Merge two or more sets of features.                        |          |\n",
        "| [SimpleImputer](SimpleImputerhttps://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)                                                                           | `impute`            | Impute missing data using descriptive statistics.          |          |\n",
        "| [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)                                                                                              | `pipeline`          | Chain methods into a pipeline.                             |          |\n",
        "| [SequentialFeatureSelector](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html#sklearn.feature_selection.SequentialFeatureSelector) | `feature_selection` | Forward and backward selection of features.                |          |\n",
        "| [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)                                             | `compose`           | Transform all feature columns.                             |          |\n",
        "| [TransformedTargetRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.compose.TransformedTargetRegressor.html#sklearn.compose.TransformedTargetRegressor)                  | `compose`           | Transform target.                                          |          |\n",
        "| [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer)                           | `preprocessing`     | Transform features using custom function.                  |          |\n",
        "| [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)                                          | `preprocessing`     | Scale features to unit variance and zero mean.             |          |\n",
        "| [SplineTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer)                                 | `preprocessing`     | Construct B-splines.                                       |          |\n",
        "| [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)                                             | `preprocessing`     | Use categorical variables.                                 |          |\n",
        "| [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures)                              | `preprocessing`     | Generate polynomial and interaction features.              |          |\n",
        "| [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer)                                    | `preprocessing`     | Construct step functions.                                  |          |\n",
        "| [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)                                                                           | `decomposition`     | Construct new features using principal component analysis. |          |"
      ],
      "id": "9c0a7b34"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}